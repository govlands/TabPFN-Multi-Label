#!/usr/bin/env python3
"""
æµ‹è¯•ç«¯åˆ°ç«¯è”åˆè®­ç»ƒæ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½
"""

import os
import torch
import numpy as np
from joint_training import main, load_model_e2e
from sklearn.datasets import make_multilabel_classification
from sklearn.metrics import accuracy_score, hamming_loss


def test_save_load():
    """æµ‹è¯•æ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½"""
    
    print("=== æµ‹è¯•ç«¯åˆ°ç«¯è”åˆè®­ç»ƒæ¨¡å‹ä¿å­˜/åŠ è½½ ===")
    
    # 1. è¿è¡Œè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
    print("\n1. å¼€å§‹è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹...")
    tabpfns, joint_model, optimizer = main()
    
    # 2. æŸ¥æ‰¾ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶
    model_files = [f for f in os.listdir("models") if f.startswith("e2e_joint_model") and f.endswith(".pt")]
    if not model_files:
        raise FileNotFoundError("æ²¡æœ‰æ‰¾åˆ°ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶")
    
    model_path = os.path.join("models", model_files[-1])  # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
    print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    # 3. åŠ è½½æ¨¡å‹
    print("\n2. åŠ è½½ä¿å­˜çš„æ¨¡å‹...")
    loaded_tabpfns, loaded_joint, loaded_optimizer, loaded_config = load_model_e2e(model_path)
    
    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹:")
    print(f"   - TabPFNåˆ†ç±»å™¨æ•°é‡: {len(loaded_tabpfns)}")
    print(f"   - è”åˆæ¨¡å‹ç±»å‹: {type(loaded_joint).__name__}")
    print(f"   - ä¼˜åŒ–å™¨ç±»å‹: {type(loaded_optimizer).__name__}")
    print(f"   - é…ç½®å‚æ•°æ•°é‡: {len(loaded_config)}")
    
    # 4. æµ‹è¯•æ¨¡å‹æ¨ç† - åˆ›å»ºä¸€äº›æµ‹è¯•æ•°æ®
    print("\n3. æµ‹è¯•æ¨¡å‹æ¨ç†...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ® (ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„å‚æ•°)
    X_test, y_test = make_multilabel_classification(
        n_samples=100,
        n_features=loaded_config.get('n_features', 20),
        n_classes=len(loaded_tabpfns),
        n_labels=2,
        random_state=42
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    X_test_tensor = torch.from_numpy(X_test).to(device=device, dtype=torch.float32)
    y_test_tensor = torch.from_numpy(y_test.astype(np.float32)).to(device=device)
    
    # ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œæ¨ç†
    with torch.no_grad():
        # æ¨¡æ‹Ÿè·å–TabPFN logitsï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…ä¸­éœ€è¦å®Œæ•´çš„forwardè¿‡ç¨‹ï¼‰
        Z_logits = torch.randn(X_test.shape[0], len(loaded_tabpfns), device=device)
        
        # é€šè¿‡è”åˆæ¨¡å‹è·å–é¢„æµ‹
        joint_logits = loaded_joint(X_test_tensor, Z_logits)
        joint_probs = torch.sigmoid(joint_logits)
        joint_preds = (joint_probs > 0.5).float()
    
    # è®¡ç®—ç®€å•çš„å‡†ç¡®æ€§æŒ‡æ ‡
    accuracy = accuracy_score(y_test, joint_preds.cpu().numpy())
    hamming = hamming_loss(y_test, joint_preds.cpu().numpy())
    
    print(f"âœ… æ¨ç†æµ‹è¯•å®Œæˆ:")
    print(f"   - æµ‹è¯•æ ·æœ¬æ•°: {X_test.shape[0]}")
    print(f"   - å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"   - HammingæŸå¤±: {hamming:.4f}")
    
    # 5. æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = model_path.replace('.pt', '_config.txt')
    if os.path.exists(config_path):
        print(f"\n4. é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_path}")
        with open(config_path, 'r') as f:
            config_content = f.read()
            print("é…ç½®æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
            print(config_content[:500] + ("..." if len(config_content) > 500 else ""))
    
    print("\nğŸ‰ ç«¯åˆ°ç«¯æ¨¡å‹ä¿å­˜/åŠ è½½æµ‹è¯•å®Œæˆï¼")
    return True


if __name__ == "__main__":
    try:
        test_save_load()
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()